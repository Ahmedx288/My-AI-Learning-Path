# Recurrent Neural Networks

Discover recurrent neural networks, a type of model that performs extremely well on temporal data, and several of its variants, including LSTMs, GRUs and Bidirectional RNNs.

**Learning Objectives**
* Define notation for building sequence models.
* Describe the architecture of a basic RNN.
* Identify the main components of an LSTM.
* Implement backpropagation through time for a basic RNN and an LSTM.
* Give examples of several types of RNN.
* Build a character-level text generation model using an RNN.
* Store text data for processing using an RNN.
* Sample novel sequences in an RNN.
* Explain the vanishing/exploding gradient problem in RNNs.
* Apply gradient clipping as a solution for exploding gradients.
* Describe the architecture of a GRU.
* Use a bidirectional RNN to take information from two points of a sequence.
* Stack multiple RNNs on top of each other to create a deep RNN.
* Use the flexible Functional API to create complex models.
* Generate your own jazz music with deep learning.
* Apply an LSTM to a music generation task.

**This week contains:** *1 Quiz & 3 Programming Exercises*

----

**Module 1: Recurrent Neural Networks**
|Lecture|Duration|
|--|--|
|Why Sequence Models?|(2 min)|
|Notation|(9 min)|
|Recurrent Neural Network Model|(16 min)|
|Backpropagation Through Time|(6 min)|
|Different Types of RNNs|(9 min)|
|Language Model and Sequence Generation|(12 min)|
|Sampling Novel Sequences|(8 min)|
|Vanishing Gradients with RNNs|(6 min)|
|Gated Recurrent Unit (GRU)|(17 min)|
|Long Short Term Memory (LSTM)|(9 min)|
|Bidirectional RNN|(8 min)|
|Deep RNNs|(5 min)|