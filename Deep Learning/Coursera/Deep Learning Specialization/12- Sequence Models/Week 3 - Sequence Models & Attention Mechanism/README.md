# Sequence Models & Attention Mechanism

Augment your sequence models using an attention mechanism, an algorithm that helps your model decide where to focus its attention given a sequence of inputs. Then, explore speech recognition and how to deal with audio data.

**Learning Objectives**
* Describe a basic sequence-to-sequence model.
* Compare and contrast several different algorithms for language translation.
* Optimize beam search and analyze it for errors.
* Use beam search to identify likely translations.
* Apply BLEU score to machine-translated text.
* Implement an attention model.
* Train a trigger word detection model and make predictions.
* Synthesize and process audio recordings to create train/dev datasets.
* Structure a speech recognition project.

**This week contains:** *1 Quiz & 2 Programming Exercises*

----

**Module 1: Various Sequence To Sequence Architectures**
|Lecture|Duration|
|--|--|
|Basic Models|(6 min)|
|Picking the Most Likely Sentence|(8 min)|
|Beam Search|(11 min)|
|Refinements to Beam Search|(11 min)|
|Error Analysis in Beam Search|(9 min)|
|Bleu Score (Optional)|(16 min)|
|Attention Model Intuition|(9 min)|
|Attention Model|(12 min)|

**Module 2: Speech Recognition - Audio Data**
|Lecture|Duration|
|--|--|
|Speech Recognition|(8 min)|
|Trigger Word Detection|(4 min)|